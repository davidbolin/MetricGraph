---
title: "Whittle--Matérn fields with general smoothness"
author: "David Bolin, Alexandre B. Simas"
date: "Created: 2022-11-23. Last modified: `r Sys.Date()`."
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Whittle--Matérn fields with general smoothness}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
references:
- id: xiong22
  title: "Covariance-based rational approximations of fractional SPDEs for computationally efficient Bayesian inference"
  author:
  - family: Bolin
    given: David  
  - family: Simas
    given: Alexandre B.
  - family: Xiong
    given: Zhen
  container-title: Journal of Computational and Graphical Statistics
  type: article
  issued:
    year: 2023
- id: graph_fem
  title: "Regularity and numerical approximation of fractional elliptic differential equations on compact metric graphs"
  author:
  - family: Bolin
    given: David
  - family: Kovács
    given: Mihály
  - family: Kumar
    given: Vivek
  - family: Simas
    given: Alexandre B.
  container-title: arXiv:2302.03995
  type: preprint
  issued:
    year: 2023
---

```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = TRUE)
  set.seed(111)
```

## Introduction

In this vignette we will introduce how to fit Whittle--Matérn fields with
general smoothness based on finite element and rational approximations.
The theory for this approach is provided in [@graph_fem](https://arxiv.org/abs/2302.03995) and
[@xiong22](https://arxiv.org/abs/2209.04670).
For the implementation, we make use of the [`rSPDE` package](https://davidbolin.github.io/rSPDE/) for the rational approximations.

These models are thus implemented using finite element approximations. Such
approximations are not needed in for integer smoothness parameters, and for 
the details about the exact models we refer to the vignettes

* [Whittle--Matérn fields on metric graphs](random_fields.html)
* [INLA and inlabru interfaces](inla_interface.html)

For details on the construction of metric graphs, see 
[Working with metric graphs](metric_graphs.html)

For further details on data manipulation on metric graphs, see 
[Data manipulation on metric graphs](metric_graph_data.html)

## Constructing the graph and the mesh
We begin by loading the `rSPDE` and `MetricGraph` packages:

```{r, message=FALSE, warning=FALSE}
  library(rSPDE)
  library(MetricGraph)
```

As an example, we consider the following metric graph
```{r, fig.show='hold',fig.align = "center",echo=TRUE}
  edge1 <- rbind(c(0,0),c(1,0))
  edge2 <- rbind(c(0,0),c(0,1))
  edge3 <- rbind(c(0,1),c(-1,1))
  theta <- seq(from=pi,to=3*pi/2,length.out = 20)
  edge4 <- cbind(sin(theta),1+ cos(theta))
  edges = list(edge1, edge2, edge3, edge4)
  graph <- metric_graph$new(edges = edges)
  graph$plot()
```

To construct a FEM approximation of a Whittle--Matérn field with general smoothness, 
we must first construct a mesh on the graph. 
```{r}
  graph$build_mesh(h = 0.5)
  graph$plot(mesh=TRUE)
```

In the command `build_mesh`, the argument `h` decides the largest spacing between nodes in
the mesh. As can be seen in the plot, the mesh is very coarse, so let's reduce the value of `h` and rebuild the mesh:
```{r}
graph$build_mesh(h = 0.01)
```

We are now ready to specify the model
$$
(\kappa^2 - \Delta)^{\alpha/2} \tau u = \mathcal{W}
$$
for the Whittle--Matérn field $u$. For this, we use the `matern.operators` function from 
the `rSPDE` package:
```{r} 
  sigma <- 1.3
  range <- 0.15
  nu <- 0.8 

  rspde.order <- 2
  op <- matern.operators(nu = nu, range = range, sigma = sigma, 
                         parameterization = "matern",
                         m = rspde.order, graph = graph)                     
```
As can be seen in the code, we specify $\kappa$ via the practical correlation range
$\sqrt{8\nu}/\kappa$. Also, the model is not parametrized by $\tau, \alpha$ but instead by 
$\sigma, \nu$. Here, `sigma` denotes the standard deviation of the field and `nu` is the smoothness parameter, which is related to $\alpha$ via the relation $\alpha = \nu + 1/2$.
The object `op_cov` contains the matrices needed for evaluating the distribution of the stochastic weights in the FEM approximation. 

Let us simulate the field $u$ at the mesh locations and plot the result:
```{r, message=FALSE} 
u <- simulate(op)
graph$plot_function(X = u, plotly = TRUE)
```

If we want to evaluate $u(s)$ at some locations $s_1,\ldots, s_n$, we need to multiply the weights with the FEM basis functions $\varphi_i(s)$ evaluated at the locations. For this, we can construct the observation matrix $\boldsymbol{\mathrm{A}}$, with elements $A_{ij} = \varphi_j(s_i)$, which links the FEM basis functions to the locations. This can be done
by the function `fem_basis` in the metric graph object. To illustrate this, let us simulate 
some observation locations on the graph and construct the matrix:
```{r} 
obs.per.edge <- 100
obs.loc <- NULL
for(i in 1:graph$nE) {
  obs.loc <- rbind(obs.loc,
                   cbind(rep(i,obs.per.edge), runif(obs.per.edge)))
}
n.obs <- obs.per.edge*graph$nE
A <- graph$fem_basis(obs.loc)
```
In the code, we generate $50$ observation locations per edge in the graph, drawn at random. It can be noted that we assume that the observation locations are given in the format $(e, d)$ where $e$ denotes the edge of the observation and $d$ is the position on the edge, i.e.,
the relative distance from the first vertex of the edge. 

To compute the precision matrix from the covariance-based rational approximation one
can use the `precision()` method on object returned by the `matern.operators()` function:

```{r}
  Q <- precision(op)
```

As an illustration of the model, let us compute the covariance function between the process at the mid point of the second edge and all other locations in the mesh. The covariances can be calculated as
$$
  \overline{\boldsymbol{\mathrm{A}}} \boldsymbol{\mathrm{Q}}^{-1}\overline{\boldsymbol{\mathrm{v}}}.
$$
Here, $\boldsymbol{\mathrm{Q}}$ is the precision matrix obtained from the rational approximation, $\boldsymbol{\mathrm{A}}$ is an identity matrix since we are evaluating the approximation in the nodes of the FEM mesh, $\overline{\boldsymbol{\mathrm{v}}}$ is the $(m+1)$-fold vertical concatenation of the vector $\boldsymbol{\mathrm{v}}$, where $\boldsymbol{\mathrm{v}}$ is a vector with all basis functions evaluated in $s=(2,0.1)$.
```{r}
  v <- t(graph$fem_basis(matrix(c(2,0.1),1,2)))
  v_bar <- kronecker(matrix(1, nrow = rspde.order + 1),
                     v)
  A_bar <- kronecker(matrix(1, ncol = rspde.order + 1), 
                     Matrix::Diagonal(dim(graph$mesh$V)[1]))
  c_cov <- (A_bar) %*% solve(Q, v_bar)
  graph$plot_function(c_cov, plotly = TRUE)
```



## Using the model for inference

There is built-in support for computing log-likelihood functions and performing kriging prediction in the `rSPDE` package which we can use for the graph model. To illustrate this, we 
use the simulation to create some noisy observations of the process. 
We generate the observations as $Y_i = 1 + 2x_{i1} - 3 x_{i2} u(s_i) + \varepsilon_i$, where $\varepsilon_i \sim N(0,\sigma_e^2)$ is Gaussian measurement noise, $x_1$ and $x_2$ are covariates generated the relative positions of the observations on the graph.
```{r}
    sigma.e <- 0.1

    x1 <- obs.loc[,1]
    x2 <- obs.loc[,2]

    Y <- 1 + 2*x1 - 3*x2 + as.vector(A %*% u + sigma.e * rnorm(n.obs))
```

Let us now fit the model. To this end we will use the `graph_lme()` function (that, for the finite element models, acts as a wrapper for the `rspde_lme()` function from the `rSPDE` package). To this end, let us now assemble the `data.frame()` with the observations, the observation locations and the covariates:
```{r}
df_data <- data.frame(y = Y, edge_number = obs.loc[,1],
                        distance_on_edge = obs.loc[,2],
                        x1 = x1, x2 = x2)
```

Let us now add the data to the graph object and plot it:

```{r}
graph$add_observations(data = df_data, normalized = TRUE)

graph$plot(data = "y")
```

We can now fit the model. To this end, we use the `graph_lme()` function and set the model to `'WM`'.
```{r}
fit <- graph_lme(y ~ x1 + x2, graph = graph, model = "WM")
```

Let us obtain a summary of the model:
```{r}
summary(fit)
```

Let us compare the values of the parameters of the latent model with the true ones:

```{r}    
print(data.frame(sigma = c(sigma, fit$matern_coeff$random_effects[2]), 
                   range = c(range, fit$matern_coeff$random_effects[3]),
                   nu = c(nu, fit$matern_coeff$random_effects[1]),
                   row.names = c("Truth", "Estimates")))
```


### Kriging
Given that we have estimated the parameters, let us compute the kriging predictor 
of the field given the observations at the mesh nodes. 

We will perform kriging with the `predict()` method. To this end, we need to provide a `data.frame` containing the prediction locations, as well as the values of the covariates at the prediction locations.

```{r}
  df_pred <- data.frame(edge_number = graph$mesh$VtE[,1],
                        distance_on_edge = graph$mesh$VtE[,2],
                        x1 = graph$mesh$VtE[,1],
                        x2 = graph$mesh$VtE[,2])

  u.krig <- predict(fit, data = df_pred, normalized = TRUE)
```

The estimate is shown in the following figure

```{r, fig.show='hold',fig.align = "center",echo=TRUE}
  graph$plot_function(as.vector(u.krig$mean))  
```

## Fitting a model with replicates

Let us now illustrate how to simulate a data set with replicates and then fit a model to such data. To simulate a latent model with replicates, all we do is set the `nsim` argument to the number of replicates.

```{r}
  n.rep <- 30
  u.rep <- simulate(op, nsim = n.rep)
```

Now, let us generate the observed values $Y$:

```{r}
  sigma.e <- 0.3
  Y.rep <- A %*% u.rep + sigma.e * matrix(rnorm(n.obs * n.rep), ncol = n.rep)
```

Note that $Y$ is a matrix with 20 columns, each column containing
one replicate. We need to turn `y` into a vector and create an auxiliary vector `repl` indexing the replicates of `y`:

```{r, message=FALSE, warning=FALSE}
y_vec <- as.vector(Y.rep)
repl <- rep(1:n.rep, each = n.obs)                       

df_data_repl <- data.frame(y = y_vec, 
                              edge_number = rep(obs.loc[,1], n.rep),
                              distance_on_edge = rep(obs.loc[,2], n.rep), 
                              repl = repl)

```

Let us clear the previous observations and add the new data to the graph:
```{r}
graph$clear_observations()
graph$add_observations(data = df_data_repl, normalized = TRUE, group = "repl")
```

We can now fit the model in the same way as before by using the `rspde_lme()` function. Note that we can optimize in parallel by setting `parallel` to `TRUE`. If we do not specify which replicate to consider, in the `which_repl` argument, all replicates will be considered.

```{r}
fit_repl <- graph_lme(y ~ -1, graph = graph, model = "WM", parallel = TRUE)
```

Let us see a summary of the fit:

```{r}
summary(fit_repl)
```

Let us compare the values of the parameters of the latent model with the true ones:

```{r}    
print(data.frame(sigma = c(sigma, fit_repl$matern_coeff$random_effects[2]), 
                   range = c(range, fit_repl$matern_coeff$random_effects[3]),
                   nu = c(nu, fit_repl$matern_coeff$random_effects[1]),
                   row.names = c("Truth", "Estimates")))
```

## Using the R-INLA implementation

We also have an `R-INLA` implementation of the rational SPDE approach
for metric graphs. 

We begin by defining the model by using the `rspde.metric_graph()` function.
This function contains the same arguments as the function
`rspde.matern()`. We refer the reader to the  [R-INLA implementation of the rational SPDE approach](https://davidbolin.github.io/rSPDE/articles/rspde_inla.html) vignette for further details.

We begin by clearing the previous observations and adding the observations (for the case without replicates) to the graph:

```{r}
graph$clear_observations()
graph$add_observations(data = df_data, normalized = TRUE)
```

Let us create the model object:
```{r, message=FALSE}
  library(INLA)
  rspde_model <- rspde.metric_graph(graph)
```

By default, the order of the rational approximation is 2.

We can now create the auxiliary quantities that will be needed with the `graph_data_rspde()` function:
```{r}
  data_rspde <- graph_data_rspde(rspde_model, name = "field")
```

The remaining is standard: we create the formula object, the 
stack object, and then fit the model by using the `inla()` function.
So, first we create the formula object:
```{r}
  f.s <- y ~ -1 + Intercept + x1 + x2 + f(field, model = rspde_model)
```
Now we create the `inla.stack` object. To such an end, observe that `data_rspde` contains the dataset as the `data` component, the index as the `index` component and the so-called `A` matrix as the `basis` component. We will now create the stack using these components:
```{r}
  stk.dat <- inla.stack(
    data = data_rspde[["data"]]["y"], A = list(data_rspde[["basis"]],1), tag = "est",
    effects =
      list(c(
        data_rspde[["index"]],
        list(Intercept = 1)), list(x1 = data_rspde[["data"]]["x1"] ,
                                      x2 = data_rspde[["data"]]["x2"])
      )
    )
```

Finally, we can fit the model:
```{r, warning=FALSE}
  rspde_fit <- inla(f.s, data = inla.stack.data(stk.dat),
    control.inla = list(int.strategy = "eb"),
    control.predictor = list(A = inla.stack.A(stk.dat), compute = TRUE)
  )
```

We can use the same functions as the `rspde` fitted models in `inla`.
For instance, we can see the results in the original scale by creating
the `result` object:
```{r}
  result_fit <- rspde.result(rspde_fit, "field", rspde_model)
  summary(result_fit)
```
Let us compare with the true values:
```{r}
  result_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, range, nu),
    mean = c(
      result_fit$summary.std.dev$mean,
      result_fit$summary.range$mean,
      result_fit$summary.nu$mean
    ),
    mode = c(
      result_fit$summary.std.dev$mode,
      result_fit$summary.range$mode,
      result_fit$summary.nu$mode
    )
  )
  print(result_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE,  warning=FALSE}
  posterior_df_fit <- gg_df(result_fit)

  library(ggplot2)

  ggplot(posterior_df_fit) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```

### Kriging with the `R-INLA` implementation

We will do kriging on the mesh locations:

```{r}
  pred_loc <- graph$mesh$VtE
```

Let us now add the observations for prediction:

```{r}
graph$add_observations(data = data.frame(y=rep(NA,nrow(pred_loc)), 
                                x1 = graph$mesh$VtE[,1],
                                x2 = graph$mesh$VtE[,2],
                                edge_number = pred_loc[,1], 
                                distance_on_edge = pred_loc[,2]), 
                                normalized = TRUE)
```

Let us now create a new model and, then, compute the auxiliary components at the prediction locations. To this end, we set the argument `only_pred` to `TRUE`, in which it will return the `data.frame` containing the 
`NA` data.

```{r}
  rspde_model_prd <- rspde.metric_graph(graph) 
  data_rspde_prd <- graph_data_rspde(rspde_model_prd, only_pred = TRUE)
```

Let us build the prediction stack using the components of `data_rspde_prd` and gather it with the estimation
stack. 
```{r}
  ef.prd <- 
    list(c(data_rspde_prd[["index"]], list(Intercept = 1)), 
          list(x1 = data_rspde_prd[["data"]][["x1"]],
                x2 = data_rspde_prd[["data"]][["x2"]]))
  stk.prd <- inla.stack(
    data = data.frame(y = data_rspde_prd[["data"]][["y"]]),
    A = list(data_rspde_prd[["basis"]],1), tag = "prd",
    effects = ef.prd
  )
  stk.all <- inla.stack(stk.dat, stk.prd)
```

Let us obtain the predictions:
```{r}
rspde_fitprd <- inla(f.s,
  data = inla.stack.data(stk.all),
  control.predictor = list(
    A = inla.stack.A(stk.all),
    compute = TRUE, link = 1
  ),
  control.compute = list(
    return.marginals = FALSE,
    return.marginals.predictor = FALSE
  ),
  control.inla = list(int.strategy = "eb")
)
```

Let us now extract the indices of the predicted nodes and store the means:
```{r}
id.prd <- inla.stack.index(stk.all, "prd")$data
m.prd <- rspde_fitprd$summary.fitted.values$mean[id.prd]
```

Finally, let us plot the predicted values. To this end 
we will use the `plot_function()` graph method. 
```{r, fig.show='hold',fig.align = "center",echo=TRUE}
  graph$plot_function(m.prd, plotly = TRUE)  
```

## Using `R-INLA` implementation to fit models with replicates

Let us begin by cloning the graph and clearing the observations on the cloned graph:

```{r}
graph_rep <- graph$clone()
graph_rep$clear_observations()
```

We will now add the data with replicates to the graph:

```{r}
graph_rep$add_observations(data = data.frame(y=as.vector(Y.rep), 
                          edge_number = rep(obs.loc[,1], n.rep), 
                          distance_on_edge = rep(obs.loc[,2], n.rep),
                          repl = rep(1:n.rep, each = n.obs)), 
                          group = "repl",
                          normalized = TRUE)
```

Let us create a new `rspde` model object:

```{r}
rspde_model_rep <- rspde.metric_graph(graph_rep)
```

To fit the model with replicates we need to create the auxiliary quantities with the `graph_data_rspde()` function, where we set the `repl` argument
in the function `graph_data_spde` to `__all` since we want to use all replicates:
```{r}
data_rspde_rep <- graph_data_rspde(rspde_model_rep, name = "field", repl = "__all")
```

Let us now create the corresponding `inla.stack` object:
```{r}
st.dat.rep <- inla.stack(
  data = data_rspde_rep[["data"]],
  A = data_rspde_rep[["basis"]],
  effects = data_rspde_rep[["index"]]
)
```
Observe that we need the response variable `y` to be a vector.
We can now create the `formula` object, remembering that since we
gave the name argument `field`, when creating the index, we need to pass
`field.repl` to the `formula`:
```{r}
f.rep <-
  y ~ -1 + f(field,
    model = rspde_model_rep,
    replicate = field.repl
  )
```
We can, finally, fit the model:
```{r}
rspde_fit_rep <-
  inla(f.rep,
    data = inla.stack.data(st.dat.rep),
    family = "gaussian",
    control.predictor =
      list(A = inla.stack.A(st.dat.rep))
  )
```

We can obtain the estimates in the original scale with the `rspde.result()` function:
```{r}
  result_fit_rep <- rspde.result(rspde_fit_rep, "field", rspde_model_rep)
  summary(result_fit_rep)
```
Let us compare with the true values of the parameters:
```{r}
  result_rep_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, range, nu),
    mean = c(
      result_fit_rep$summary.std.dev$mean,
      result_fit_rep$summary.range$mean,
      result_fit_rep$summary.nu$mean
    ),
    mode = c(
      result_fit_rep$summary.std.dev$mode,
      result_fit_rep$summary.range$mode,
      result_fit_rep$summary.nu$mode
    )
  )
  print(result_rep_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE,  warning=FALSE}
  posterior_df_fit_rep <- gg_df(result_fit_rep)

  ggplot(posterior_df_fit_rep) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```



## Using `inlabru` implementation

The `inlabru` package allows us to fit models and do kriging in a 
straighforward manner, without having to handle `A` matrices,
indices nor `inla.stack` objects. Therefore, we suggest
the reader to use this implementation when using our
implementation to fit real data.

Let us clear the graph, since it contains `NA` observations we used for prediction, add the observations again,
and create a new `rSPDE` model object:
```{r}
graph$clear_observations()
graph$add_observations(data = df_data, 
                          normalized = TRUE)
rspde_model <- rspde.metric_graph(graph)
```
Let us now load the `inlabru` package and create the component (which is `inlabru`'s formula-like object). Since we are using the data from the graph,
`inlabru` will also obtain the locations from the graph, thus, there is no need to provide the locations. However, we need a name for the locations 
for using inlabru's `predict` method. Therefore, we can choose any name for the location that is not a name being used in the graph's data. In our
case we will use the name `loc`:
```{r}
    library(inlabru)
    cmp <-
    y ~ -1 + Intercept(1) + x1 + x2 + field(loc, 
                          model = rspde_model)                   
```

Let us now build the auxiliary data to be used with the `graph_data_rspde()` function, where we pass the name of the location variable in the above formula as the `loc_name` argument, which in this case is `"loc"`:
```{r}
data_rspde_bru <- graph_data_rspde(rspde_model, loc_name = "loc")
```

Now, we can directly fit the model of the
`graph_data_spde()` function:
```{r}
  rspde_bru_fit <-
    bru(cmp,
        data=data_rspde_bru[["data"]],
      options=list(
      family = "gaussian")
    )
```
Let us now obtain the estimates of the parameters in the
original scale by using the `rspde.result()` function:
```{r}
  result_bru_fit <- rspde.result(rspde_bru_fit, "field", rspde_model)
  summary(result_bru_fit)
```
Let us compare with the true values of the parameters:
```{r}
  result_bru_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, range, nu),
    mean = c(
      result_bru_fit$summary.std.dev$mean,
      result_bru_fit$summary.range$mean,
      result_bru_fit$summary.nu$mean
    ),
    mode = c(
      result_bru_fit$summary.std.dev$mode,
      result_bru_fit$summary.range$mode,
      result_bru_fit$summary.nu$mode
    )
  )
  print(result_bru_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE,  warning=FALSE}
  posterior_df_bru_fit <- gg_df(result_bru_fit)

  ggplot(posterior_df_bru_fit) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```

### Kriging with the `inlabru` implementation

It is very easy to do kriging with the `inlabru` implementation.
We simply need to provide the prediction locations to the
`predict()` method.

In this example we will use the mesh locations. To this end we will
use the `get_mesh_locations()` method. We also set `bru=TRUE` and `loc="loc"` to obtain a data list suitable to be used with `inlabru`.
```{r}
  data_prd_list <- graph$get_mesh_locations(bru = TRUE,
                                            loc = "loc")
  data_prd_list[["x1"]] <- data_prd_list$loc[,1]
  data_prd_list[["x2"]] <- data_prd_list$loc[,2]
```
Now, we can simply provide these locations to the `predict` method
along with the fitted object `rspde_bru_fit`:
```{r}
  y_pred <- predict(rspde_model, cmp, rspde_bru_fit, newdata=data_prd_list, ~Intercept + x1 + x2 + field)
```

Finally, let us plot the predicted values. To this end 
we will use the `plot()` method on `y_pred`: 
```{r, fig.show='hold',fig.align = "center",echo=TRUE}
  plot(y_pred, plotly = TRUE, support_width=0)  
```

## Using inlabru to fit models with replicates

We can also use our `inlabru` implementation to fit models with replicates. We will
consider the same data that was generated above, where the number of replicates is 30.

For this implementation we will use the `rspde_model_rep` object.

We can now create the component, passing the vector with the indices of the replicates
as the `replicate` argument. To obtain the auxiliary data, we will pass `repl` argument we use the function
`graph_data_rspde()`, where we set it to `__all`, since we want all replicates. Further, we also pass the `loc_name` argument.
```{r}
data_rspde_rep <- graph_data_rspde(rspde_model_rep, repl = "__all", loc_name = "loc")
```

We can now define the `bru` component formula, passing the `repl` component of `data_rspde_rep` as the `replicate` argument:
```{r}
  cmp_rep <-
    y ~ -1 + field(loc, model = rspde_model_rep,
                              replicate = data_rspde_rep[["repl"]])
```
Now, we are ready to fit the model:
```{r}
  rspde_bru_fit_rep <-
    bru(cmp_rep,
        data=data_rspde_rep[["data"]],
      options=list(
      family = "gaussian")
    )
```

We can obtain the estimates in the original scale with the `rspde.result()` function:
```{r}
  result_bru_fit_rep <- rspde.result(rspde_bru_fit_rep, "field", rspde_model_rep)
  summary(result_bru_fit_rep)
```
Let us compare with the true values of the parameters:
```{r}
  result_bru_rep_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, range, nu),
    mean = c(
      result_bru_fit_rep$summary.std.dev$mean,
      result_bru_fit_rep$summary.range$mean,
      result_bru_fit_rep$summary.nu$mean
    ),
    mode = c(
      result_bru_fit_rep$summary.std.dev$mode,
      result_bru_fit_rep$summary.range$mode,
      result_bru_fit_rep$summary.nu$mode
    )
  )
  print(result_bru_rep_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE,  warning=FALSE}
  posterior_df_bru_fit_rep <- gg_df(result_bru_fit_rep)

  ggplot(posterior_df_bru_fit_rep) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```





## References

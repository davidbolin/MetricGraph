---
title: "Whittle--Matérn fields with general smoothness"
author: "David Bolin, Alexandre B. Simas"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{General smoothness}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
references:
- id: xiong22
  title: "Covariance-based rational approximations of fractional SPDEs for computationally efficient Bayesian inference"
  author:
  - family: Xiong
    given: Zhen
  - family: Simas
    given: Alexandre B.
  - family: Bolin
    given: David
  container-title: arXiv:2209.04670
  type: preprint
  issued:
  year: 2022
- id: graph_fem
  title: "Regularity and numerical approximation of fractional elliptic differential equations on compact metric graphs"
  author:
  - family: Bolin
    given: David
  - family: Kovács
    given: Mihály
  - family: Kumar
    given: Vivek
  - family: Simas
    given: Alexandre B.
  container-title: arXiv:??
  type: preprint
  issued:
  year: 2022
---

```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = TRUE)
  set.seed(1)
```

## Introduction

In this vignette we will introduce how to fit Whittle--Matérn fields with
general smoothness based on finite element and rational approximations.
The theory for this approach is provided in [@graph_fem](??) and
[@xiong22](https://arxiv.org/abs/2209.04670).
For the implementation, make use of the `rSPDE` package for the rational approximations.


## Constructing the graph and the mesh
We begin by loading the `rSPDE` and `GPGraph` packages:

```{r, message=FALSE, warning=FALSE}
  library(rSPDE)
  library(GPGraph)
```

As an example, we consider the following metric graph
```{r}
  line1 <- Line(rbind(c(0,0),c(1,0)))
  line2 <- Line(rbind(c(0,0),c(0,1)))
  line3 <- Line(rbind(c(0,1),c(-1,1)))
  theta <- seq(from=pi,to=3*pi/2,length.out = 20)
  line4 <- Line(cbind(sin(theta),1+ cos(theta)))
  Lines = sp::SpatialLines(list(Lines(list(line1),ID="1"),
                                Lines(list(line2),ID="2"),
                                Lines(list(line3),ID="3"),
                                Lines(list(line4),ID="4")))
  graph <- metric_graph$new(Lines = Lines)
  graph$plot(line_width = 0.3, show = FALSE)
```

To construct a FEM approximation of a Whittle--Matérn field with general smoothness, 
we must first construct a mesh on the graph. 
```{r}
  graph$build_mesh(h = 0.5)
  graph$plot(mesh=TRUE,line_width = 0.5, marker_size = 3, show = FALSE)
```

In the command `build_mesh`, the argument `h` decides the largest spacing between nodes in
the mesh. As can be seen in the plot, the mesh is very coarse, so let's reduce the value of `h` and rebuild the mesh:
```{r}
  graph$build_mesh(h = 0.01)
```

The next step is to build the mass and stiffness matrices for the FEM basis.
```{r}
  graph$compute_fem()
```

We are now ready to specify the model
$$
(\kappa^2 - \Delta)^{\alpha} \tau u = \mathcal{W}
$$
for the Whittle--Matérn field $u$. For this, we use the `matern.operators` function from 
the `rSPDE` package:
```{r} 
  sigma <- 1
  r <- 0.2
  nu <- 0.9
  rspde.order <- 2
  kappa <- sqrt(8 * nu) / r
  op <- matern.operators(C= graph$mesh$C, G = graph$mesh$G, d = 1, 
                         nu = nu, kappa = kappa, sigma = sigma, m = rspde.order)
```
As can be seen in the code, we specify $\kappa$ via the practical correlation range
$\sqrt{8\nu}/\kappa$. Also, the model is not parametrized by $\tau, \alpha$ but instead by 
$\sigma, \nu$. Here, `sigma` denotes the standard deviation of the field and `nu` is the smoothness parameter, which is related to $\alpha$ via the relation $\alpha = \nu + 1/2$.
The object `op_cov` contains the matrices needed for evaluating the distribution of the stochastic weights in the FEM approximation. 

Let us simulate the field $u$ at the mesh locations and plot the result:
```{r} 
u <- simulate(op)
graph$plot_function_mesh(u, plotly = TRUE)
```

If we want to evaluate $u(s)$ at some locations $s_1,\ldots, s_n$, we need to multiply the weights with the FEM basis functions $\varphi_i(s)$ evaluated at the locations. For this, we can construct the observation matrix $\boldsymbol{\mathrm{A}}$, with elements $A_{ij} = \varphi_j(s_i)$, which links the FEM basis functions to the locations. This can be done
by the function `mesh_A` in the metric graph object. To illustrate this, let us simulate 
some observation locations on the graph and construct the matrix:
```{r} 
obs.per.edge <- 50
obs.loc <- NULL
for(i in 1:graph$nE) {
  obs.loc <- rbind(obs.loc,
                   cbind(rep(i,obs.per.edge), runif(obs.per.edge)))
}
n.obs <- obs.per.edge*graph$nE
A <- graph$mesh_A(obs.loc)
```
In the code, we generate $50$ observation locations per edge in the graph, drawn at random. It can be noted that we assume that the observation locations are given in the format $(e, d)$ where $e$ denotes the edge of the observation and $d$ is the position on the edge, i.e.,
the relative distance from the first vertex of the edge. 

To compute the precision matrix from the covariance-based rational approximation one
can use the `precision()` method on object returned by the `matern.operators()` function:

```{r}
  Q <- precision(op)
```

As an illustration of the model, let us compute the covariance function between the process at the mid point of the second edge and all other locations in the mesh. The covariances can be calculated as
$$
  \overline{\boldsymbol{\mathrm{A}}} \boldsymbol{\mathrm{Q}}^{-1}\overline{\boldsymbol{\mathrm{v}}}.
$$
Here, $\boldsymbol{\mathrm{Q}}$ is the precision matrix obtained from the rational approximation, $\boldsymbol{\mathrm{A}}$ is an identity matrix since we are evaluating the approximation in the nodes of the FEM mesh, $\overline{\boldsymbol{\mathrm{v}}}$ is the $(m+1)$-fold vertical concatenation of the vector $\boldsymbol{\mathrm{v}}$, where $\boldsymbol{\mathrm{v}}$ is a vector with all basis functions evaluated in $s=0.5$.
```{r}
  v <- t(graph$mesh_A(matrix(c(2,0.5),1,2)))
  v_bar <- kronecker(matrix(1, nrow = rspde.order + 1),
                     v)
  A_bar <- kronecker(matrix(1, ncol = rspde.order + 1), 
                     Diagonal(dim(graph$mesh$V)[1]))
  c_cov <- (A_bar) %*% solve(Q, v_bar)
  graph$plot_function_mesh(c_cov, plotly = TRUE)
```



## Using the model for inference

There is built-in support for computing log-likelihood functions and performing kriging prediction in the `rSPDE` package which we can use for the graph model. To illustrate this, we use the simulation to create some noisy observations of the process. 
We generate the observations as $Y_i = u(s_i) + \varepsilon_i$, where $\varepsilon_i \sim N(0,\sigma_e^2)$ is Gaussian measurement noise. 
```{r}
    sigma.e <- 0.1
    Y <- as.vector(A %*% u + sigma.e * rnorm(n.obs))
```

Let us now fit the model. To this end we first must compute the loglikelihood function
as function of the parameters we want to estimate. We define
the loglikelihood function parametrized using the logarithm of each
parameter to avoid constrained optimization.

    ```{r}
    mlik <- rSPDE.construct.matern.loglike(op, Y=Y, A=A)
    ```

We now set some suitable initial values for the optimization and fit the 
model using `optim`.

```{r, message=FALSE, warning=FALSE}
  theta0 <- c(log(sqrt(var(as.vector(Y)))),
              log(10),
              log(1),
              log(0.1 * sqrt(var(as.vector(Y)))))

  theta <- optim(theta0, mlik, method = "L-BFGS-B")
    
  print(data.frame(sigma = c(sigma, exp(theta$par[1])), 
                   kappa = c(kappa, exp(theta$par[2])),
                   nu = c(nu, exp(theta$par[3])),
                   sigma.e = c(sigma.e, exp(theta$par[4])),
                   row.names = c("Truth", "Estimates")))
```

### Kriging
Given that we have estimated the parameters, let us compute the kriging predictor 
of the field given the observations at the mesh nodes. 

Let us update the model object with the fitted parameters:

```{r}
  sigma_est <- exp(theta$par[1])
  kappa_est <- exp(theta$par[2])
  nu_est <- exp(theta$par[3])

  op_cov <- update(op,
                   user_kappa = kappa_est,
                   user_sigma = sigma_est,
                   user_nu = nu_est)
```

We can now perform kriging with the `predict()` method:

```{r}
  u.krig <- predict(op, A = A, Aprd = Diagonal(op$sizeC), Y = Y, sigma.e = sigma.e)
```
Since we predicted at the mesh nodes, `Aprd` was chosen as the identity matrix with the size of the mesh. If we wish to predict at some other locations, we can simply change `Aprd` to be the observation matrix for those locations.

The estimate is shown in the following figure

```{r, fig.show='hold',fig.align = "center",echo=TRUE}
  graph$plot_function_mesh(as.vector(u.krig[[1]]), plotly = TRUE)  
```

## Fitting a model with replicates

Let us now illustrate how to simulate a data set with replicates and then fit a model to such data. To simulate a latent model with replicates, all we do is set the `nsim` argument to the number of replicates.

```{r}
  n.rep <- 30
  u.rep <- simulate(op, nsim = n.rep)
```

Now, let us generate the observed values $Y$:

```{r}
  sigma.e <- 0.3
  Y.rep <- A %*% u.rep + sigma.e * matrix(rnorm(n.obs * n.rep), ncol = n.rep)
```

Note that $Y$ is a matrix with 20 columns, each column containing
one replicate. Now, the remaining of the code is identical to the previous case.
The `rSPDE.matern.loglike()` function automatically identifies the replicates
from the fact that $Y$ is a matrix with more than one column.

```{r, message=FALSE, warning=FALSE}
  theta0 <- c(log(sqrt(var(as.vector(Y)))),
              log(10),
              log(1),
              log(0.1 * sqrt(var(as.vector(Y)))))

    mlik <- rSPDE.construct.matern.loglike(op_cov, Y=Y.rep, A=A)

    theta <- optim(theta0, mlik, method = "L-BFGS-B")
    
    print(data.frame(sigma = c(sigma, exp(theta$par[1])),
                     kappa = c(kappa, exp(theta$par[2])),
                     nu = c(nu, exp(theta$par[3])),
                     sigma.e = c(sigma.e, exp(theta$par[4])),
                     row.names = c("Truth", "Estimates")))
```

## Using the R-INLA implementation

We also have an `R-INLA` implementation of the rational SPDE approach
for metric graphs. 

We begin by defining the model by using the `rspde.metric_graph()` function.
This function contains the same arguments as the function
`rspde.matern()`. We refer the reader to the  [R-INLA implementation of the rational SPDE approach](https://davidbolin.github.io/rSPDE/articles/rspde_inla.html) vignette for further details.

Let us create the model object:
```{r}
  rspde_model <- rspde.metric_graph(graph)
```

By default, the order of the rational approximation is 2.

We can now create the `A` matrix and the index object by using
the same functions as for the rational SPDE approach, namely,
`rspde.make.A()` and `rspde.make.index()`, supplying the 
graph object as the mesh argument. Here we create the `A` matrix:
```{r}
  Abar <- rspde.make.A(graph, loc=obs.loc)
```

Now, let us create the index object:
```{r}
  rspde.index <- rspde.make.index(name="field", mesh=graph)
```

The remaining is standard: we create the formula object, the 
stack object, and then fit the model by using the `inla()` function.
So, first we create the formula object:
```{r}
  f.s <- y ~ -1 + Intercept + f(field, model = rspde_model)
```
Now we create the `inla.stack` object:
```{r}
  stk.dat <- inla.stack(
    data = list(y = Y), A = Abar, tag = "est",
    effects =
      c(
        rspde.index,
        list(Intercept = 1)
      )
    )
```

Finally, we can fit the model:
```{r, warning=FALSE}
  rspde_fit <- inla(f.s, data = inla.stack.data(stk.dat),
    control.inla = list(int.strategy = "eb"),
    control.predictor = list(A = inla.stack.A(stk.dat), compute = TRUE),
              inla.mode = "experimental"
  )
```

We can use the same functions as the `rspde` fitted models in `inla`.
For instance, we can see the results in the original scale by creating
the `result` object:
```{r}
  result_fit <- rspde.result(rspde_fit, "field", rspde_model)
  summary(result_fit)
```
Let us compare with the true values:
```{r}
  result_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, r, nu),
    mean = c(
      result_fit$summary.std.dev$mean,
      result_fit$summary.range$mean,
      result_fit$summary.nu$mean
    ),
    mode = c(
      result_fit$summary.std.dev$mode,
      result_fit$summary.range$mode,
      result_fit$summary.nu$mode
    )
  )
  print(result_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE, fig.width=7}
  posterior_df_fit <- gg_df(result_fit)

  ggplot(posterior_df_fit) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```

### Kriging with the `R-INLA` implementation

We will do kriging on the mesh locations:

```{r}
  pred_loc <- graph$mesh$VtE
```

Let us compute the `A` matrix at the prediction locations:

```{r}
  Abar_prd <- rspde.make.A(graph, loc=pred_loc)
```

Let us build the prediction stack and gather it with the estimation
stack:
```{r}
  ef.prd <- 
    c(rspde.index, list(Intercept = 1))
  stk.prd <- inla.stack(
    data = list(y = NA),
    A = Abar_prd, tag = "prd",
    effects = ef.prd
  )
  stk.all <- inla.stack(stk.dat, stk.prd)
```

Let us obtain the predictions:
```{r}
rspde_fitprd <- inla(f.s,
  data = inla.stack.data(stk.all),
  control.predictor = list(
    A = inla.stack.A(stk.all),
    compute = TRUE, link = 1
  ),
  control.compute = list(
    return.marginals = FALSE,
    return.marginals.predictor = FALSE
  ),
  control.inla = list(int.strategy = "eb")
)
```

Let us now extract the indices of the predicted nodes and store the means:
```{r}
id.prd <- inla.stack.index(stk.all, "prd")$data
m.prd <- rspde_fitprd$summary.fitted.values$mean[id.prd]
```

Finally, let us plot the predicted values. To this end 
we will use the `plot_function_mesh()` graph method. 
```{r, fig.show='hold',fig.align = "center",echo=TRUE}
  graph$plot_function_mesh(m.prd, plotly = TRUE)  
```

## Using `R-INLA` implementation to fit models with replicates

To fit the model with replicates we need to create the corresponding `A` matrix and
`index` object:
```{r}
Abar.rep <- rspde.make.A(
  mesh = graph, loc = obs.loc, index = rep(1:200, times = n.rep),
  repl = rep(1:n.rep, each = 200)
)

mesh.index.rep <- rspde.make.index(
  name = "field", mesh = graph,
  n.repl = n.rep
)
```

Let us now create the corresponding `inla.stack` object:
```{r}
st.dat.rep <- inla.stack(
  data = list(y = as.vector(Y.rep), loc=obs.loc),
  A = Abar.rep,
  effects = mesh.index.rep
)
```
Observe that we need the response variable `y` to be a vector.
We can now create the `formula` object, remembering that since we
gave the name argument `field`, when creating the index, we need to pass
`field.repl` to the `formula`:
```{r}
f.rep <-
  y ~ -1 + f(field,
    model = rspde_model,
    replicate = field.repl
  )
```
We can, finally, fit the model:
```{r}
rspde_fit_rep <-
  inla(f.rep,
    data = inla.stack.data(st.dat.rep),
    family = "gaussian",
    control.predictor =
      list(A = inla.stack.A(st.dat.rep)),
            inla.mode = "experimental"
  )
```

We can obtain the estimates in the original scale with the `rspde.result()` function:
```{r}
  result_fit_rep <- rspde.result(rspde_fit_rep, "field", rspde_model)
  summary(result_fit_rep)
```
Let us compare with the true values of the parameters:
```{r}
  result_rep_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, r, nu),
    mean = c(
      result_fit_rep$summary.std.dev$mean,
      result_fit_rep$summary.range$mean,
      result_fit_rep$summary.nu$mean
    ),
    mode = c(
      result_fit_rep$summary.std.dev$mode,
      result_fit_rep$summary.range$mode,
      result_fit_rep$summary.nu$mode
    )
  )
  print(result_rep_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE, fig.width=7}
  posterior_df_fit_rep <- gg_df(result_fit_rep)

  ggplot(posterior_df_fit_rep) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```



## Using `inlabru` implementation

The `inlabru` package allows us to fit models and do kriging in a 
straighforward manner, without having to handle `A` matrices,
indices nor `inla.stack` objects. Therefore, we suggest
the reader to use this implementation when using our
implementation to fit real data.

We first load the `inlabru` package, and create the `data`
object containing the response variable `y` and the observation
locations:
```{r, message=FALSE}
    library(inlabru)
    data_list <- list(y=Y, loc = obs.loc)
```
Now we create the component (which is `inlabru`'s formula-like object).
Observe that we are using the `rspde_model` object created
with the `rspde.metric_graph()` function.
```{r}
    cmp <-
    y ~ -1 + Intercept(1) + field(loc, model = rspde_model)
```
Now, we can directly fit the model:
```{r}
  rspde_bru_fit <-
    bru(cmp,
        data=data_list,
      options=list(
      family = "gaussian",
      inla.mode = "experimental")
    )
```
Let us now obtain the estimates of the parameters in the
original scale by using the `rspde.result()` function:
```{r}
  result_bru_fit <- rspde.result(rspde_bru_fit, "field", rspde_model)
  summary(result_bru_fit)
```
Let us compare with the true values of the parameters:
```{r}
  result_bru_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, r, nu),
    mean = c(
      result_bru_fit$summary.std.dev$mean,
      result_bru_fit$summary.range$mean,
      result_bru_fit$summary.nu$mean
    ),
    mode = c(
      result_bru_fit$summary.std.dev$mode,
      result_bru_fit$summary.range$mode,
      result_bru_fit$summary.nu$mode
    )
  )
  print(result_bru_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE, fig.width=7}
  posterior_df_bru_fit <- gg_df(result_bru_fit)

  ggplot(posterior_df_bru_fit) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```

### Kriging with the `inlabru` implementation

It is very easy to do kriging with the `inlabru` implementation.
We simply need to provide the prediction locations to the
`predict()` method.

In this example we will use the mesh locations:
```{r}
  pred_loc <- graph$mesh$VtE
  data_prd_list <- list(loc = pred_loc)
```
Now, we can simply provide these locations to the `predict` method
along with the fitted object `rspde_bru_fit`:
```{r}
  field_pred <- predict(rspde_bru_fit, data=data_prd_list, ~field)
```

Finally, let us plot the predicted values. To this end 
we will use the `plot_function()` graph method: 
```{r, fig.show='hold',fig.align = "center",echo=TRUE}
  graph$plot_function_mesh(field_pred$mean, plotly = TRUE)  
```

## Using inlabru to fit models with replicates

We can also use our `inlabru` implementation to fit models with replicates. We will
consider the same data that was generated above, where the number of replicates is 30.

We begin by creating the data list containing the responses and the locations:
```{r}
   n.rep <- 30
   obs.loc.rep <- obs.loc
   for(i in 2:n.rep){
    obs.loc.rep <- rbind(obs.loc.rep, obs.loc)
   }

   data_list_rep <- list(y = as.vector(Y.rep),
                            loc = obs.loc.rep)
```
Observe that the response, `y`, needs to be a vector.

Let us now create the vector indexing the replicates:
```{r}  
  repl <- rep(1:n.rep, each=200)
```
We can now create the component, passing the vector with the indices of the replicates
as the `replicate` argument:
```{r}
  cmp_rep <-
    y ~ -1 + Intercept(1) + field(obs.loc.rep, model = rspde_model,
                                    replicate = repl)
```
Now, we are ready to fit the model:
```{r}
  rspde_bru_fit_rep <-
    bru(cmp_rep,
        data=data_list_rep,
      options=list(
      family = "gaussian",
      inla.mode = "experimental")
    )
```

We can obtain the estimates in the original scale with the `rspde.result()` function:
```{r}
  result_bru_fit_rep <- rspde.result(rspde_bru_fit_rep, "field", rspde_model)
  summary(result_bru_fit_rep)
```
Let us compare with the true values of the parameters:
```{r}
  result_bru_rep_df <- data.frame(
    parameter = c("std.dev", "range", "nu"),
    true = c(sigma, r, nu),
    mean = c(
      result_bru_fit_rep$summary.std.dev$mean,
      result_bru_fit_rep$summary.range$mean,
      result_bru_fit_rep$summary.nu$mean
    ),
    mode = c(
      result_bru_fit_rep$summary.std.dev$mode,
      result_bru_fit_rep$summary.range$mode,
      result_bru_fit_rep$summary.nu$mode
    )
  )
  print(result_bru_rep_df)
```

We can also plot the posterior marginal densities with the 
help of the `gg_df()` function:
```{r, fig.show='hold',fig.align = "center",echo=TRUE, fig.width=7}
  posterior_df_bru_fit_rep <- gg_df(result_bru_fit_rep)

  ggplot(posterior_df_bru_fit_rep) + geom_line(aes(x = x, y = y)) + 
  facet_wrap(~parameter, scales = "free") + labs(y = "Density")
```





## References
